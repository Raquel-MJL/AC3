# robots.txt para controlar el acceso de los robots de búsqueda

# Por defecto, ningún robot puede rastrear el sitio web
User-agent: *
Disallow: /

# Exabot, MetaURI y Rogerbot pueden rastrear las carpetas 'buscadores' y 'navegadores'
User-agent: Exabot
Allow: /buscadores/
Allow: /navegadores/

User-agent: MetaURI
Allow: /buscadores/
Allow: /navegadores/

User-agent: Rogerbot
Allow: /buscadores/
Allow: /navegadores/

# Los robots pueden acceder a los archivos en 'Varios' cuyos nombres empiezan por 'doc'
User-agent: *
Allow: /Varios/doc*

# Permitir acceso a imágenes en 'imagenes' solo al robot de Google para imágenes
User-agent: Googlebot-Image
Allow: /imagenes/

# Bloquear el acceso a la carpeta 'imagenes' para el resto de los robots
User-agent: *
Disallow: /imagenes/

# Permitir a los robots de Bing y Yandex acceder a imágenes con extensión '.png'
User-agent: Bingbot
Allow: /*.png$

User-agent: Yandex
Allow: /*.png$

# Todos los robots pueden rastrear el archivo 'descargas.html' en la carpeta 'descargas'
User-agent: *
Allow: /descargas/descargas.html
